#version 460 core
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : enable
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_ray_query: require

#include "debug.glsl"

#define SPATIAL_RECONSTRUCTION_SAMPLES 8
#define SPARTIAL_RECONSTRUCTION_RADIUS 4.
#define SPATIAL_RECONSTRUCTION_ROUGHNESS_FACTOR 5.
#define SPATIAL_RECONSTRUCTION_SIGMA 0.9
#define INDIRECT_SCALE 2
//#define SSR_OPTION_HALF_RESOLUTION 1

#define GLSL
#include "ray_interop.h"
#undef GLSL

#define RAY_BOUNCE
#define RAY_QUERY
layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

layout(set = 0, binding = 0, rgba16f) uniform image2D out_indirect_specular_reconstructed;

layout(set = 0, binding = 1, rgba32f) uniform readonly image2D position_t;
layout(set = 0, binding = 2, rgba16f) uniform readonly image2D normals_gs;
layout(set = 0, binding = 3, rgba8) uniform readonly image2D material_rmxx;
layout(set = 0, binding = 4, rgba16f) uniform readonly image2D indirect_specular;
layout(set = 0, binding = 5, rgba32f) uniform readonly image2D reflection_direction_pdf;

layout(set = 0, binding = 6) uniform UBO { UniformBuffer ubo; } ubo;

#include "utils.glsl"
#include "noise.glsl"
#include "brdf.glsl"

#ifndef PI
	#define PI 3.14 // FIXME please
#endif

void readNormals(ivec2 uv, out vec3 geometry_normal, out vec3 shading_normal) {
	const vec4 n = imageLoad(normals_gs, uv);
	geometry_normal = normalDecode(n.xy);
	shading_normal = normalDecode(n.zw);
}

struct PixelAreaStatistic
{
    float Mean;
    float Variance;
    float WeightSum;
    vec4 ColorSum;
};

float ComputeGaussianWeight(float Distance)
{
    return exp(-0.66 * Distance * Distance); // assuming Distance is normalized to 1
}

// vec4 ComputeBlurKernelRotation(ivec2 pix, uint FrameIndex)
// {
//     float Angle = Bayer4x4(pix, FrameIndex);
//     return GetRotator(2.0 * PI * Angle);
// }

// Visibility = G2(v,l,a) / (4 * (n,v) * (n,l))
// see https://google.github.io/filament/Filament.md.html#materialsystem/specularbrdf
float SmithGGXVisibilityCorrelated(float NdotL, float NdotV, float AlphaRoughness)
{
    // G1 (masking) is % microfacets visible in 1 direction
    // G2 (shadow-masking) is % microfacets visible in 2 directions
    // If uncorrelated:
    //    G2(NdotL, NdotV) = G1(NdotL) * G1(NdotV)
    //    Less realistic as higher points are more likely visible to both L and V
    //
    // https://ubm-twvideo01.s3.amazonaws.com/o1/vault/gdc2017/Presentations/Hammon_Earl_PBR_Diffuse_Lighting.pdf

    float a2 = AlphaRoughness * AlphaRoughness;

    float GGXV = NdotL * sqrt(max(NdotV * NdotV * (1.0 - a2) + a2, 1e-7));
    float GGXL = NdotV * sqrt(max(NdotL * NdotL * (1.0 - a2) + a2, 1e-7));

    return 0.5 / (GGXV + GGXL);
}

// The following equation(s) model the distribution of microfacet normals across the area being drawn (aka D())
// Implementation from "Average Irregularity Representation of a Roughened Surface for Ray Reflection" by T. S. Trowbridge, and K. P. Reitz
// Follows the distribution function recommended in the SIGGRAPH 2013 course notes from EPIC Games, Equation 3.
float NormalDistribution_GGX(float NdotH, float AlphaRoughness)
{
    // "Sampling the GGX Distribution of Visible Normals" (2018) by Eric Heitz - eq. (1)
    // https://jcgt.org/published/0007/04/01/

    // Make sure we reasonably handle AlphaRoughness == 0
    // (which corresponds to delta function)
    AlphaRoughness = max(AlphaRoughness, 1e-3);

    float a2  = AlphaRoughness * AlphaRoughness;
    float nh2 = NdotH * NdotH;
    float f   = nh2 * a2 + (1.0 - nh2);
    return a2 / max(PI * f * f, 1e-9);
}

vec2 ComputeWeightRayLength(ivec2 pix, vec3 V, vec3 N, float roughness, float NdotV, float Weight)
{
    vec4 RayDirectionPDF = imageLoad(reflection_direction_pdf, pix);
    float InvRayLength = inversesqrt(dot(RayDirectionPDF.xyz, RayDirectionPDF.xyz));
    if (isnan(InvRayLength))
    {
        return vec2(1.0e-6f, 1.0e-6f);
    }
    else
    {
        vec3 RayDirection = RayDirectionPDF.xyz * InvRayLength;
        float PDF = RayDirectionPDF.w;
        float AlphaRoughness = roughness * roughness;

        vec3 L = RayDirection;
        vec3 H = normalize(L + V);

        float NdotH = saturate(dot(N, H));
        float NdotL = saturate(dot(N, L));

        float Vis = SmithGGXVisibilityCorrelated(NdotL, NdotV, AlphaRoughness);
        float D = NormalDistribution_GGX(NdotH, AlphaRoughness);
        float LocalBRDF = Vis * D * NdotL;
        LocalBRDF *= ComputeGaussianWeight(Weight);
		float rcpRayLength = InvRayLength == 0. ? 0. : 1. / InvRayLength;
        return vec2(max(LocalBRDF / max(PDF, 1.0e-5f), 1e-6), 1. / InvRayLength);
    }

	return vec2(0.);
}

// Weighted incremental variance
// https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance
void ComputeWeightedVariance(inout PixelAreaStatistic Stat, vec4 SampleColor, float Weight)
{
    Stat.ColorSum += Weight * SampleColor;
    Stat.WeightSum += Weight;

    float Value = luminance(SampleColor.rgb);
    float PrevMean = Stat.Mean;

	float rcpWeightSum = Stat.WeightSum == 0. ? 0. : 1. / Stat.WeightSum;

    Stat.Mean += Weight * rcpWeightSum * (Value - PrevMean);
    Stat.Variance += Weight * (Value - PrevMean) * (Value - Stat.Mean);
}

float ComputeResolvedDepth(vec3 origin, vec3 PositionWS, float SurfaceHitDistance)
{
	return distance(origin, PositionWS) + SurfaceHitDistance;
    //float CameraSurfaceDistance = distance(origin, PositionWS) + SurfaceHitDistance;
    //return CameraZToDepth(CameraSurfaceDistance + SurfaceHitDistance, g_Camera.mProj);
}

ivec2 ClampScreenCoord(ivec2 pix, ivec2 res)\
{
	return max(ivec2(0), min(ivec2(res - 1), pix));
}


float ComputeSpatialWeight(float Distance, float Sigma)
{
    return exp(-(Distance) / (2.0 * Sigma * Sigma));
}

void main() {
	const ivec2 pix = ivec2(gl_GlobalInvocationID);
	const ivec2 res = ubo.ubo.res / INDIRECT_SCALE;
	if (any(greaterThanEqual(pix, res))) {
		return;
	}

	if ((ubo.ubo.renderer_flags & RENDERER_FLAG_SPARTIAL_RECONSTRUCTION) == 0) {
	    imageStore(out_indirect_specular_reconstructed, pix, imageLoad(indirect_specular, pix));
        return;
    }

	const vec2 uv = (gl_GlobalInvocationID.xy + .5) / res * 2. - 1.;
	
	const vec3 origin = (ubo.ubo.inv_view * vec4(0, 0, 0, 1)).xyz;
	const vec3 position = imageLoad(position_t, pix).xyz;

    // samples = 8, min distance = 0.5, average samples on radius = 2
    vec3 Poisson[SPATIAL_RECONSTRUCTION_SAMPLES];
    Poisson[0] = vec3(-0.4706069, -0.4427112, +0.6461146);
    Poisson[1] = vec3(-0.9057375, +0.3003471, +0.9542373);
    Poisson[2] = vec3(-0.3487388, +0.4037880, +0.5335386);
    Poisson[3] = vec3(+0.1023042, +0.6439373, +0.6520134);
    Poisson[4] = vec3(+0.5699277, +0.3513750, +0.6695386);
    Poisson[5] = vec3(+0.2939128, -0.1131226, +0.3149309);
    Poisson[6] = vec3(+0.7836658, -0.4208784, +0.8895339);
    Poisson[7] = vec3(+0.1564120, -0.8198990, +0.8346850);

	vec3 geometry_normal, shading_normal;
	readNormals(pix, geometry_normal, shading_normal);

    vec3 V = normalize(origin - position);
    float NdotV = saturate(dot(shading_normal, V));

    float roughness = imageLoad(material_rmxx, pix).x;

    float roughness_factor = saturate(float(SPATIAL_RECONSTRUCTION_ROUGHNESS_FACTOR) * roughness);
    float radius = mix(0.0, SPARTIAL_RECONSTRUCTION_RADIUS, roughness_factor);
    //vec4 Rotator = ComputeBlurKernelRotation(pix, g_Camera.uiFrameIndex);

    PixelAreaStatistic PixelAreaStat;
    PixelAreaStat.ColorSum = vec4(0.0, 0.0, 0.0, 0.0);
    PixelAreaStat.WeightSum = 0.0;
    PixelAreaStat.Variance = 0.0;
    PixelAreaStat.Mean = 0.0;

    float NearestSurfaceHitDistance = 0.0;

	vec3 result_color = vec3(0.);
	float weights_sum = 0.;

    // TODO: Try to implement sampling from https://youtu.be/MyTOGHqyquU?t=1043
    for (int SampleIdx = 0; SampleIdx < SPATIAL_RECONSTRUCTION_SAMPLES; SampleIdx++)
    {
		vec2 Xi = Poisson[SampleIdx].xy;
        //vec2 Xi = RotateVector(Rotator, Poisson[SampleIdx].xy); // TODO: rotate samples
// #ifdef SSR_OPTION_HALF_RESOLUTION
//         ivec2 SampleCoord = ClampScreenCoord(ivec2(0.5 * (vec2(pix) + radius * Xi) + vec2(0.5, 0.5)), ivec2(res));
// #else
        ivec2 SampleCoord = ClampScreenCoord(ivec2(vec2(pix) + radius * Xi), res);
//#endif
        float WeightS = ComputeSpatialWeight(Poisson[SampleIdx].z * Poisson[SampleIdx].z, SPATIAL_RECONSTRUCTION_SIGMA);
        vec2 WeightLength = ComputeWeightRayLength(SampleCoord, V, shading_normal, roughness, NdotV, WeightS);
        vec4 SampleColor = imageLoad(indirect_specular, SampleCoord);
        ComputeWeightedVariance(PixelAreaStat, SampleColor, WeightLength.x);

        if (WeightLength.x > 1.0e-6)
            NearestSurfaceHitDistance = max(WeightLength.y, NearestSurfaceHitDistance);

		result_color += SampleColor.xyz * WeightLength.x;
		weights_sum += WeightLength.x;
    }

	if (weights_sum > 0.) {
		result_color /= weights_sum;
	}

    vec4 ResolvedRadiance = PixelAreaStat.ColorSum / max(PixelAreaStat.WeightSum, 1e-6f);
    float ResolvedVariance = PixelAreaStat.Variance / max(PixelAreaStat.WeightSum, 1e-6f);
    float ResolvedDepth = ComputeResolvedDepth(origin, position, NearestSurfaceHitDistance);

	imageStore(out_indirect_specular_reconstructed, pix, vec4(ResolvedRadiance.xyz, ResolvedVariance));
}
